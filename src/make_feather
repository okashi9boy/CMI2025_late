{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":102335,"databundleVersionId":12518947,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":14806046,"sourceType":"datasetVersion","datasetId":9467211}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Kaggleの仕様上、**`/kaggle/input/` ディレクトリは読み取り専用 (Read-only)** です。\n\nそのため、データセットを作成するフローは以下のようになります。\n\n1.  ノートブック上で特徴量を生成し、**`/kaggle/working/`** (出力ディレクトリ) にFeather形式で保存する。\n2.  ノートブックを「Save Version」で実行する。\n3.  実行完了後、Outputタブから「New Dataset」を作成する。\n4.  次のノートブックでそのDatasetを読み込む（ここで初めて `/kaggle/input/my-new-dataset/` として使えるようになります）。\n\n以下に、**メモリ効率を考慮し、特徴量ごとに個別のFeatherファイルとして保存する** Pythonコードのテンプレートを提案します。\n\n### 特徴量生成・保存用コード\n\nこのコードは、TrainとTestを結合して特徴量を作り、元のインデックスに戻してから列ごとにFeatherファイルとして保存する構成になっています。\n","metadata":{}},{"cell_type":"code","source":"import os\nimport glob\n\nfiles = glob.glob('/kaggle/working/features/*')\nfor f in files:\n    if os.path.isfile(f):\n        os.remove(f)\n    elif os.path.isdir(f):\n        import shutil\n        shutil.rmtree(f)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T12:05:36.814186Z","iopub.execute_input":"2026-02-11T12:05:36.814452Z","iopub.status.idle":"2026-02-11T12:05:36.859386Z","shell.execute_reply.started":"2026-02-11T12:05:36.814429Z","shell.execute_reply":"2026-02-11T12:05:36.858036Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport gc\nfrom pathlib import Path\n\n# ==========================================\n# 設定\n# ==========================================\nCOMPETITION_NAME = \"competitions/cmi-detect-behavior-with-sensor-data\" \nINPUT_PATH = Path(f\"/kaggle/input/{COMPETITION_NAME}\")\n\n# ルート出力ディレクトリ\nOUTPUT_PATH = Path(\"/kaggle/working/features\")\n\n# ==========================================\n# ユーティリティ関数\n# ==========================================\ndef load_dataset_with_len(train_file, test_file):\n    \"\"\"\n    指定されたファイル名のtrain/testデータを読み込み、\n    trainの行数と共に返す\n    \"\"\"\n    train_path = INPUT_PATH / train_file\n    test_path = INPUT_PATH / test_file\n    \n    if not train_path.exists() or not test_path.exists():\n        print(f\"[Warning] {train_file} or {test_file} not found. Skipping...\")\n        return None, None, 0\n    \n    print(f\"Loading {train_file} and {test_file}...\")\n    train = pd.read_csv(train_path)\n    test = pd.read_csv(test_path)\n    \n    train_len = len(train)\n    return train, test, train_len\n\ndef save_feature_split(df_feature, feature_name, sub_folder, train_len):\n    \"\"\"\n    特徴量を train / test に分割し、それぞれのフォルダ構造に保存する\n    \n    Args:\n        df_feature (pd.DataFrame): 全結合された特徴量データ\n        feature_name (str): 特徴量ファイル名\n        sub_folder (str): データ由来のフォルダ名 (\"main\" or \"demographics\")\n        train_len (int): trainデータの行数（分割位置）\n    \"\"\"\n    # インデックスをリセット\n    df_feature = df_feature.reset_index(drop=True)\n    \n    # --- Trainデータの保存 ---\n    df_train = df_feature.iloc[:train_len].reset_index(drop=True)\n    \n    # 保存先: features/train/{sub_folder}/\n    train_dir = OUTPUT_PATH / \"train\" / sub_folder\n    train_dir.mkdir(parents=True, exist_ok=True)\n    \n    save_path_train = train_dir / f\"{feature_name}.feather\"\n    df_train.to_feather(save_path_train)\n    \n    # --- Testデータの保存 ---\n    df_test = df_feature.iloc[train_len:].reset_index(drop=True)\n    \n    # 保存先: features/test/{sub_folder}/\n    test_dir = OUTPUT_PATH / \"test\" / sub_folder\n    test_dir.mkdir(parents=True, exist_ok=True)\n    \n    save_path_test = test_dir / f\"{feature_name}.feather\"\n    df_test.to_feather(save_path_test)\n    \n    print(f\"Saved: {feature_name} (Train: {len(df_train)}, Test: {len(df_test)})\")\n\n# ==========================================\n# 特徴量生成プロセス\n# ==========================================\n\ndef process_main_features(full_data, train_len):\n    \"\"\"メインデータの特徴量を作成し、train/testフォルダに分けて保存\"\"\"\n    print(\"\\n=== Processing Main Data Features ===\")\n    SUB_FOLDER = \"main\"\n    \n    processed_cols = set()\n\n    # 1. ToFセンサー (まとめて保存)\n    for i in range(1, 6):\n        prefix = f\"tof_{i}_\"\n        target_cols = [c for c in full_data.columns if c.startswith(prefix)]\n        \n        if len(target_cols) > 0:\n            feat_name = f\"tof_{i}\"\n            print(f\"Processing {feat_name}...\")\n            \n            df_feat = full_data[target_cols].astype(np.float32)\n            \n            save_feature_split(df_feat, feat_name, SUB_FOLDER, train_len)\n            \n            processed_cols.update(target_cols)\n            del df_feat\n            gc.collect()\n\n    # 2. その他の列 (個別に保存)\n    remaining_cols = [c for c in full_data.columns if c not in processed_cols]\n    \n    for col in remaining_cols:\n        series = full_data[col]\n        df_feat = pd.DataFrame()\n        \n        # 型判定\n        if pd.api.types.is_numeric_dtype(series):\n            # ID系や整数で残すべきもの以外はfloat32化\n            if \"id\" in col and \"acc\" not in col and \"rot\" not in col and \"thm\" not in col:\n                 df_feat[col] = series\n            else:\n                 df_feat[col] = series.astype(np.float32)\n        else:\n            # カテゴリ化\n            df_feat[col] = series.astype('category') # .cat.codes\n            \n        save_feature_split(df_feat, col, SUB_FOLDER, train_len)\n        \n        del df_feat, series\n        gc.collect()\n\ndef process_demographics_features(base_df, train_len):\n    \"\"\"Demographics特徴量を作成し、train/testフォルダに分けて保存\"\"\"\n    print(\"\\n=== Processing Demographics Data ===\")\n    SUB_FOLDER = \"demographics\"\n    \n    # 1. 読み込み & 結合\n    train_demo, test_demo, _ = load_dataset_with_len(\"train_demographics.csv\", \"test_demographics.csv\")\n    if train_demo is None: return\n\n    full_demo = pd.concat([train_demo, test_demo], axis=0, ignore_index=True)\n    \n    # 2. 集約 (subject単位)\n    print(\"Grouping demographics by subject...\")\n    demo_grouped = full_demo.groupby('subject').first().reset_index()\n    \n    del train_demo, test_demo, full_demo\n    gc.collect()\n    \n    # 3. Mainデータの構造に合わせてマージ\n    print(\"Merging demographics onto main data structure...\")\n    merge_base = base_df[['subject']].copy()\n    merged_df = pd.merge(merge_base, demo_grouped, on='subject', how='left')\n    \n    if 'subject' in merged_df.columns:\n        del merged_df['subject']\n\n    # 4. 保存\n    for col in merged_df.columns:\n        feat_name = f\"demo_{col}\"\n        \n        series = merged_df[col]\n        df_feat = pd.DataFrame()\n\n        if pd.api.types.is_numeric_dtype(series):\n            df_feat[feat_name] = series.astype(np.float32)\n        else:\n            df_feat[feat_name] = series.astype('category').cat.codes\n            \n        save_feature_split(df_feat, feat_name, SUB_FOLDER, train_len)\n        \n        del df_feat\n        gc.collect()\n\n    del merged_df, demo_grouped, merge_base\n    gc.collect()\n\ndef main():\n    # 1. メインデータの読み込み (Trainの長さを取得)\n    print(\"Loading Main Data...\")\n    train, test, train_len = load_dataset_with_len(\"train.csv\", \"test.csv\")\n    \n    if train is None: return\n\n    # 全結合\n    full_data = pd.concat([train, test], axis=0, ignore_index=True)\n    \n    del train, test\n    gc.collect()\n\n    # 2. Mainデータ処理\n    process_main_features(full_data, train_len)\n    \n    # 3. Demographicsデータ処理\n    process_demographics_features(full_data, train_len)\n\n    print(\"-\" * 30)\n    print(f\"All features saved to {OUTPUT_PATH}\")\n    print(f\"  - Train Main: {OUTPUT_PATH / 'train' / 'main'}\")\n    print(f\"  - Train Demo: {OUTPUT_PATH / 'train' / 'demographics'}\")\n    print(f\"  - Test Main : {OUTPUT_PATH / 'test' / 'main'}\")\n    print(f\"  - Test Demo : {OUTPUT_PATH / 'test' / 'demographics'}\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T12:08:10.612654Z","iopub.execute_input":"2026-02-11T12:08:10.612964Z","iopub.status.idle":"2026-02-11T12:08:28.038236Z","shell.execute_reply.started":"2026-02-11T12:08:10.612938Z","shell.execute_reply":"2026-02-11T12:08:28.037130Z"}},"outputs":[{"name":"stdout","text":"Loading Main Data...\nLoading train.csv and test.csv...\n\n=== Processing Main Data Features ===\nProcessing tof_1...\nSaved: tof_1 (Train: 574945, Test: 107)\nProcessing tof_2...\nSaved: tof_2 (Train: 574945, Test: 107)\nProcessing tof_3...\nSaved: tof_3 (Train: 574945, Test: 107)\nProcessing tof_4...\nSaved: tof_4 (Train: 574945, Test: 107)\nProcessing tof_5...\nSaved: tof_5 (Train: 574945, Test: 107)\nSaved: row_id (Train: 574945, Test: 107)\nSaved: sequence_type (Train: 574945, Test: 107)\nSaved: sequence_id (Train: 574945, Test: 107)\nSaved: sequence_counter (Train: 574945, Test: 107)\nSaved: subject (Train: 574945, Test: 107)\nSaved: orientation (Train: 574945, Test: 107)\nSaved: behavior (Train: 574945, Test: 107)\nSaved: phase (Train: 574945, Test: 107)\nSaved: gesture (Train: 574945, Test: 107)\nSaved: acc_x (Train: 574945, Test: 107)\nSaved: acc_y (Train: 574945, Test: 107)\nSaved: acc_z (Train: 574945, Test: 107)\nSaved: rot_w (Train: 574945, Test: 107)\nSaved: rot_x (Train: 574945, Test: 107)\nSaved: rot_y (Train: 574945, Test: 107)\nSaved: rot_z (Train: 574945, Test: 107)\nSaved: thm_1 (Train: 574945, Test: 107)\nSaved: thm_2 (Train: 574945, Test: 107)\nSaved: thm_3 (Train: 574945, Test: 107)\nSaved: thm_4 (Train: 574945, Test: 107)\nSaved: thm_5 (Train: 574945, Test: 107)\n\n=== Processing Demographics Data ===\nLoading train_demographics.csv and test_demographics.csv...\nGrouping demographics by subject...\nMerging demographics onto main data structure...\nSaved: demo_adult_child (Train: 574945, Test: 107)\nSaved: demo_age (Train: 574945, Test: 107)\nSaved: demo_sex (Train: 574945, Test: 107)\nSaved: demo_handedness (Train: 574945, Test: 107)\nSaved: demo_height_cm (Train: 574945, Test: 107)\nSaved: demo_shoulder_to_wrist_cm (Train: 574945, Test: 107)\nSaved: demo_elbow_to_wrist_cm (Train: 574945, Test: 107)\n------------------------------\nAll features saved to /kaggle/working/features\n  - Train Main: /kaggle/working/features/train/main\n  - Train Demo: /kaggle/working/features/train/demographics\n  - Test Main : /kaggle/working/features/test/main\n  - Test Demo : /kaggle/working/features/test/demographics\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"### ポイントと解説\n\n1.  **保存場所 (`OUTPUT_PATH`)**:\n    *   `/kaggle/working/features` に保存するようにしています。\n    *   実行後、右側のサイドバーの「Output」セクションに `features` フォルダと `.feather` ファイルが表示されます。\n\n2.  **型変換 (`astype(np.float32)`)**:\n    *   Kaggleではメモリ制限が厳しいため、デフォルトの `float64` ではなく `float32` にキャストしてから保存することを強く推奨します。ファイルサイズも半分になります。\n\n3.  **Feather形式の利点**:\n    *   CSVに比べて読み書きが非常に高速です。\n    *   Pandasのデータ型（カテゴリー型など）を保持できます。\n    *   **重要**: Featherはindex情報を保持しない（デフォルトのRangeIndexになる）ことが多いため、読み込む際は「行順が変わっていないこと」が前提になります。上記のコードでは `concat` して上から順に保存しているため、読み込み時も同じ順序で読み込めば問題ありません。\n\n4.  **Datasetの作成方法**:\n    *   コードを実行し、正常終了したら右上の **[Save Version]** をクリックし、\"Save & Run All (Commit)\" を選択します。\n    *   処理が終わったら、作成されたVersionのViewerページに行き、**[Output]** タブを開きます。","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}