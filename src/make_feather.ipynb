{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38c8c165",
   "metadata": {
    "papermill": {
     "duration": 0.002715,
     "end_time": "2026-02-11T12:19:04.705295",
     "exception": false,
     "start_time": "2026-02-11T12:19:04.702580",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Kaggleの仕様上、**`/kaggle/input/` ディレクトリは読み取り専用 (Read-only)** です。\n",
    "\n",
    "そのため、データセットを作成するフローは以下のようになります。\n",
    "\n",
    "1.  ノートブック上で特徴量を生成し、**`/kaggle/working/`** (出力ディレクトリ) にFeather形式で保存する。\n",
    "2.  ノートブックを「Save Version」で実行する。\n",
    "3.  実行完了後、Outputタブから「New Dataset」を作成する。\n",
    "4.  次のノートブックでそのDatasetを読み込む（ここで初めて `/kaggle/input/my-new-dataset/` として使えるようになります）。\n",
    "\n",
    "以下に、**メモリ効率を考慮し、特徴量ごとに個別のFeatherファイルとして保存する** Pythonコードのテンプレートを提案します。\n",
    "\n",
    "### 特徴量生成・保存用コード\n",
    "\n",
    "このコードは、TrainとTestを結合して特徴量を作り、元のインデックスに戻してから列ごとにFeatherファイルとして保存する構成になっています。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9d48fb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T12:19:04.710569Z",
     "iopub.status.busy": "2026-02-11T12:19:04.710206Z",
     "iopub.status.idle": "2026-02-11T12:19:04.719482Z",
     "shell.execute_reply": "2026-02-11T12:19:04.718572Z"
    },
    "papermill": {
     "duration": 0.014185,
     "end_time": "2026-02-11T12:19:04.721335",
     "exception": false,
     "start_time": "2026-02-11T12:19:04.707150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "files = glob.glob('/kaggle/working/features/*')\n",
    "for f in files:\n",
    "    if os.path.isfile(f):\n",
    "        os.remove(f)\n",
    "    elif os.path.isdir(f):\n",
    "        import shutil\n",
    "        shutil.rmtree(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd894156",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T12:19:04.726832Z",
     "iopub.status.busy": "2026-02-11T12:19:04.726473Z",
     "iopub.status.idle": "2026-02-11T12:19:44.625180Z",
     "shell.execute_reply": "2026-02-11T12:19:44.624119Z"
    },
    "papermill": {
     "duration": 39.904378,
     "end_time": "2026-02-11T12:19:44.627530",
     "exception": false,
     "start_time": "2026-02-11T12:19:04.723152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Main Data...\n",
      "Loading train.csv and test.csv...\n",
      "\n",
      "=== Processing Main Data Features ===\n",
      "Processing tof_1...\n",
      "Saved: tof_1 (Train: 574945, Test: 107)\n",
      "Processing tof_2...\n",
      "Saved: tof_2 (Train: 574945, Test: 107)\n",
      "Processing tof_3...\n",
      "Saved: tof_3 (Train: 574945, Test: 107)\n",
      "Processing tof_4...\n",
      "Saved: tof_4 (Train: 574945, Test: 107)\n",
      "Processing tof_5...\n",
      "Saved: tof_5 (Train: 574945, Test: 107)\n",
      "Saved: row_id (Train: 574945, Test: 107)\n",
      "Saved: sequence_type (Train: 574945, Test: 107)\n",
      "Saved: sequence_id (Train: 574945, Test: 107)\n",
      "Saved: sequence_counter (Train: 574945, Test: 107)\n",
      "Saved: subject (Train: 574945, Test: 107)\n",
      "Saved: orientation (Train: 574945, Test: 107)\n",
      "Saved: behavior (Train: 574945, Test: 107)\n",
      "Saved: phase (Train: 574945, Test: 107)\n",
      "Saved: gesture (Train: 574945, Test: 107)\n",
      "Saved: acc_x (Train: 574945, Test: 107)\n",
      "Saved: acc_y (Train: 574945, Test: 107)\n",
      "Saved: acc_z (Train: 574945, Test: 107)\n",
      "Saved: rot_w (Train: 574945, Test: 107)\n",
      "Saved: rot_x (Train: 574945, Test: 107)\n",
      "Saved: rot_y (Train: 574945, Test: 107)\n",
      "Saved: rot_z (Train: 574945, Test: 107)\n",
      "Saved: thm_1 (Train: 574945, Test: 107)\n",
      "Saved: thm_2 (Train: 574945, Test: 107)\n",
      "Saved: thm_3 (Train: 574945, Test: 107)\n",
      "Saved: thm_4 (Train: 574945, Test: 107)\n",
      "Saved: thm_5 (Train: 574945, Test: 107)\n",
      "\n",
      "=== Processing Demographics Data ===\n",
      "Loading train_demographics.csv and test_demographics.csv...\n",
      "Grouping demographics by subject...\n",
      "Merging demographics onto main data structure...\n",
      "Saved: demo_adult_child (Train: 574945, Test: 107)\n",
      "Saved: demo_age (Train: 574945, Test: 107)\n",
      "Saved: demo_sex (Train: 574945, Test: 107)\n",
      "Saved: demo_handedness (Train: 574945, Test: 107)\n",
      "Saved: demo_height_cm (Train: 574945, Test: 107)\n",
      "Saved: demo_shoulder_to_wrist_cm (Train: 574945, Test: 107)\n",
      "Saved: demo_elbow_to_wrist_cm (Train: 574945, Test: 107)\n",
      "------------------------------\n",
      "All features saved to /kaggle/working/features\n",
      "  - Train Main: /kaggle/working/features/train/main\n",
      "  - Train Demo: /kaggle/working/features/train/demographics\n",
      "  - Test Main : /kaggle/working/features/test/main\n",
      "  - Test Demo : /kaggle/working/features/test/demographics\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "from pathlib import Path\n",
    "\n",
    "# ==========================================\n",
    "# 設定\n",
    "# ==========================================\n",
    "COMPETITION_NAME = \"competitions/cmi-detect-behavior-with-sensor-data\" \n",
    "INPUT_PATH = Path(f\"/kaggle/input/{COMPETITION_NAME}\")\n",
    "\n",
    "# ルート出力ディレクトリ\n",
    "OUTPUT_PATH = Path(\"/kaggle/working/features\")\n",
    "\n",
    "# ==========================================\n",
    "# ユーティリティ関数\n",
    "# ==========================================\n",
    "def load_dataset_with_len(train_file, test_file):\n",
    "    \"\"\"\n",
    "    指定されたファイル名のtrain/testデータを読み込み、\n",
    "    trainの行数と共に返す\n",
    "    \"\"\"\n",
    "    train_path = INPUT_PATH / train_file\n",
    "    test_path = INPUT_PATH / test_file\n",
    "    \n",
    "    if not train_path.exists() or not test_path.exists():\n",
    "        print(f\"[Warning] {train_file} or {test_file} not found. Skipping...\")\n",
    "        return None, None, 0\n",
    "    \n",
    "    print(f\"Loading {train_file} and {test_file}...\")\n",
    "    train = pd.read_csv(train_path)\n",
    "    test = pd.read_csv(test_path)\n",
    "    \n",
    "    train_len = len(train)\n",
    "    return train, test, train_len\n",
    "\n",
    "def save_feature_split(df_feature, feature_name, sub_folder, train_len):\n",
    "    \"\"\"\n",
    "    特徴量を train / test に分割し、それぞれのフォルダ構造に保存する\n",
    "    \n",
    "    Args:\n",
    "        df_feature (pd.DataFrame): 全結合された特徴量データ\n",
    "        feature_name (str): 特徴量ファイル名\n",
    "        sub_folder (str): データ由来のフォルダ名 (\"main\" or \"demographics\")\n",
    "        train_len (int): trainデータの行数（分割位置）\n",
    "    \"\"\"\n",
    "    # インデックスをリセット\n",
    "    df_feature = df_feature.reset_index(drop=True)\n",
    "    \n",
    "    # --- Trainデータの保存 ---\n",
    "    df_train = df_feature.iloc[:train_len].reset_index(drop=True)\n",
    "    \n",
    "    # 保存先: features/train/{sub_folder}/\n",
    "    train_dir = OUTPUT_PATH / \"train\" / sub_folder\n",
    "    train_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    save_path_train = train_dir / f\"{feature_name}.feather\"\n",
    "    df_train.to_feather(save_path_train)\n",
    "    \n",
    "    # --- Testデータの保存 ---\n",
    "    df_test = df_feature.iloc[train_len:].reset_index(drop=True)\n",
    "    \n",
    "    # 保存先: features/test/{sub_folder}/\n",
    "    test_dir = OUTPUT_PATH / \"test\" / sub_folder\n",
    "    test_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    save_path_test = test_dir / f\"{feature_name}.feather\"\n",
    "    df_test.to_feather(save_path_test)\n",
    "    \n",
    "    print(f\"Saved: {feature_name} (Train: {len(df_train)}, Test: {len(df_test)})\")\n",
    "\n",
    "# ==========================================\n",
    "# 特徴量生成プロセス\n",
    "# ==========================================\n",
    "\n",
    "def process_main_features(full_data, train_len):\n",
    "    \"\"\"メインデータの特徴量を作成し、train/testフォルダに分けて保存\"\"\"\n",
    "    print(\"\\n=== Processing Main Data Features ===\")\n",
    "    SUB_FOLDER = \"main\"\n",
    "    \n",
    "    processed_cols = set()\n",
    "\n",
    "    # 1. ToFセンサー (まとめて保存)\n",
    "    for i in range(1, 6):\n",
    "        prefix = f\"tof_{i}_\"\n",
    "        target_cols = [c for c in full_data.columns if c.startswith(prefix)]\n",
    "        \n",
    "        if len(target_cols) > 0:\n",
    "            feat_name = f\"tof_{i}\"\n",
    "            print(f\"Processing {feat_name}...\")\n",
    "            \n",
    "            df_feat = full_data[target_cols].astype(np.float32)\n",
    "            \n",
    "            save_feature_split(df_feat, feat_name, SUB_FOLDER, train_len)\n",
    "            \n",
    "            processed_cols.update(target_cols)\n",
    "            del df_feat\n",
    "            gc.collect()\n",
    "\n",
    "    # 2. その他の列 (個別に保存)\n",
    "    remaining_cols = [c for c in full_data.columns if c not in processed_cols]\n",
    "    \n",
    "    for col in remaining_cols:\n",
    "        series = full_data[col]\n",
    "        df_feat = pd.DataFrame()\n",
    "        \n",
    "        # 型判定\n",
    "        if pd.api.types.is_numeric_dtype(series):\n",
    "            # ID系や整数で残すべきもの以外はfloat32化\n",
    "            if \"id\" in col and \"acc\" not in col and \"rot\" not in col and \"thm\" not in col:\n",
    "                 df_feat[col] = series\n",
    "            else:\n",
    "                 df_feat[col] = series.astype(np.float32)\n",
    "        else:\n",
    "            # カテゴリ化\n",
    "            df_feat[col] = series.astype('category') # .cat.codes\n",
    "            \n",
    "        save_feature_split(df_feat, col, SUB_FOLDER, train_len)\n",
    "        \n",
    "        del df_feat, series\n",
    "        gc.collect()\n",
    "\n",
    "def process_demographics_features(base_df, train_len):\n",
    "    \"\"\"Demographics特徴量を作成し、train/testフォルダに分けて保存\"\"\"\n",
    "    print(\"\\n=== Processing Demographics Data ===\")\n",
    "    SUB_FOLDER = \"demographics\"\n",
    "    \n",
    "    # 1. 読み込み & 結合\n",
    "    train_demo, test_demo, _ = load_dataset_with_len(\"train_demographics.csv\", \"test_demographics.csv\")\n",
    "    if train_demo is None: return\n",
    "\n",
    "    full_demo = pd.concat([train_demo, test_demo], axis=0, ignore_index=True)\n",
    "    \n",
    "    # 2. 集約 (subject単位)\n",
    "    print(\"Grouping demographics by subject...\")\n",
    "    demo_grouped = full_demo.groupby('subject').first().reset_index()\n",
    "    \n",
    "    del train_demo, test_demo, full_demo\n",
    "    gc.collect()\n",
    "    \n",
    "    # 3. Mainデータの構造に合わせてマージ\n",
    "    print(\"Merging demographics onto main data structure...\")\n",
    "    merge_base = base_df[['subject']].copy()\n",
    "    merged_df = pd.merge(merge_base, demo_grouped, on='subject', how='left')\n",
    "    \n",
    "    if 'subject' in merged_df.columns:\n",
    "        del merged_df['subject']\n",
    "\n",
    "    # 4. 保存\n",
    "    for col in merged_df.columns:\n",
    "        feat_name = f\"demo_{col}\"\n",
    "        \n",
    "        series = merged_df[col]\n",
    "        df_feat = pd.DataFrame()\n",
    "\n",
    "        if pd.api.types.is_numeric_dtype(series):\n",
    "            df_feat[feat_name] = series.astype(np.float32)\n",
    "        else:\n",
    "            df_feat[feat_name] = series.astype('category').cat.codes\n",
    "            \n",
    "        save_feature_split(df_feat, feat_name, SUB_FOLDER, train_len)\n",
    "        \n",
    "        del df_feat\n",
    "        gc.collect()\n",
    "\n",
    "    del merged_df, demo_grouped, merge_base\n",
    "    gc.collect()\n",
    "\n",
    "def main():\n",
    "    # 1. メインデータの読み込み (Trainの長さを取得)\n",
    "    print(\"Loading Main Data...\")\n",
    "    train, test, train_len = load_dataset_with_len(\"train.csv\", \"test.csv\")\n",
    "    \n",
    "    if train is None: return\n",
    "\n",
    "    # 全結合\n",
    "    full_data = pd.concat([train, test], axis=0, ignore_index=True)\n",
    "    \n",
    "    del train, test\n",
    "    gc.collect()\n",
    "\n",
    "    # 2. Mainデータ処理\n",
    "    process_main_features(full_data, train_len)\n",
    "    \n",
    "    # 3. Demographicsデータ処理\n",
    "    process_demographics_features(full_data, train_len)\n",
    "\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"All features saved to {OUTPUT_PATH}\")\n",
    "    print(f\"  - Train Main: {OUTPUT_PATH / 'train' / 'main'}\")\n",
    "    print(f\"  - Train Demo: {OUTPUT_PATH / 'train' / 'demographics'}\")\n",
    "    print(f\"  - Test Main : {OUTPUT_PATH / 'test' / 'main'}\")\n",
    "    print(f\"  - Test Demo : {OUTPUT_PATH / 'test' / 'demographics'}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb8e5e0",
   "metadata": {
    "papermill": {
     "duration": 0.002763,
     "end_time": "2026-02-11T12:19:44.633167",
     "exception": false,
     "start_time": "2026-02-11T12:19:44.630404",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### ポイントと解説\n",
    "\n",
    "1.  **保存場所 (`OUTPUT_PATH`)**:\n",
    "    *   `/kaggle/working/features` に保存するようにしています。\n",
    "    *   実行後、右側のサイドバーの「Output」セクションに `features` フォルダと `.feather` ファイルが表示されます。\n",
    "\n",
    "2.  **型変換 (`astype(np.float32)`)**:\n",
    "    *   Kaggleではメモリ制限が厳しいため、デフォルトの `float64` ではなく `float32` にキャストしてから保存することを強く推奨します。ファイルサイズも半分になります。\n",
    "\n",
    "3.  **Feather形式の利点**:\n",
    "    *   CSVに比べて読み書きが非常に高速です。\n",
    "    *   Pandasのデータ型（カテゴリー型など）を保持できます。\n",
    "    *   **重要**: Featherはindex情報を保持しない（デフォルトのRangeIndexになる）ことが多いため、読み込む際は「行順が変わっていないこと」が前提になります。上記のコードでは `concat` して上から順に保存しているため、読み込み時も同じ順序で読み込めば問題ありません。\n",
    "\n",
    "4.  **Datasetの作成方法**:\n",
    "    *   コードを実行し、正常終了したら右上の **[Save Version]** をクリックし、\"Save & Run All (Commit)\" を選択します。\n",
    "    *   処理が終わったら、作成されたVersionのViewerページに行き、**[Output]** タブを開きます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55f1b7b",
   "metadata": {
    "papermill": {
     "duration": 0.002512,
     "end_time": "2026-02-11T12:19:44.638286",
     "exception": false,
     "start_time": "2026-02-11T12:19:44.635774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 12518947,
     "isSourceIdPinned": false,
     "sourceId": 102335,
     "sourceType": "competition"
    },
    {
     "datasetId": 9467211,
     "sourceId": 14806046,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31259,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 44.037384,
   "end_time": "2026-02-11T12:19:45.262309",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-02-11T12:19:01.224925",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
